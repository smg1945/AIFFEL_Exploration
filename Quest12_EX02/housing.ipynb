{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad52896e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 모듈 불러오기\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os.path import join\n",
    "\n",
    "import missingno as msno\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0bf84bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train 데이터와 test 데이터 경로를 지정한다.\n",
    "data_dir = 'C:/Users/ZAKAR/Documents/GitHub/AIFFEL/Exploration/Quest12_EX02/data'\n",
    "train_data_path = join(data_dir, 'train.csv')\n",
    "sub_data_path = join(data_dir, 'test.csv')\n",
    "# train.csv는 train 데이터로, test.csv는 sub 데이터로 지정한다.\n",
    "data = pd.read_csv(train_data_path)\n",
    "sub = pd.read_csv(sub_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9020f806",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 타겟 데이터인 price 컬럼은 y 변수에 따로 저장해준 후 데이터셋에서 제거한다.\n",
    "# price를 로그 변환하여 정규분포를 따르게 한다.\n",
    "y = data['price']\n",
    "y = np.log1p(y)\n",
    "del data['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41a3013",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train 데이터와 test 데이터를 pd.concat 메서드로 병합한다.\n",
    "data = pd.concat((data, sub), axis=0)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d862dc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 컬럼별 결측치 개수를 확인한다. 이후 타겟인 price와 상관관계가 없어 보이는\n",
    "# id 컬럼을 데이터에서 제거한다.\n",
    "for i in data.columns:\n",
    "    print('{} : {}'.format(i, len(data.loc[pd.isnull(data[i]), i].values)))\n",
    "del data['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9312ab49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# date 컬럼의 각 데이터에 포함되어 있는, 쓸모없는 부분은 지워준다.\n",
    "del data['date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b51bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 컬럼들마다 한쪽으로 치우친 분포를 보이는 데이터가 있는지 확인하기 위해\n",
    "# 서브플롯을 그려주고 seaborn의 kdeplot으로 각 컬럼들의 데이터의 그래프를 그려본다.\n",
    "fig, ax = plt.subplots(9, 2, figsize=(12, 50))\n",
    "count = 1\n",
    "columns = data.columns\n",
    "for row in range(9):\n",
    "    for col in range(2):\n",
    "        sns.kdeplot(data=data[columns[count]], ax=ax[row][col])\n",
    "        ax[row][col].set_title(columns[count], fontsize=15)\n",
    "        count += 1\n",
    "        if count == 19 :\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034bc6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 치우친 분포를 보이는 컬럼들을 skew_columns에 모아 리스트를 만든다.\n",
    "skew_columns = ['bedrooms', 'sqft_living', 'sqft_lot', 'sqft_above', 'sqft_basement', 'sqft_lot15', 'sqft_living15']\n",
    "\n",
    "# 해당 컬럼들을 하나씩 뽑아 로그 변환을 해주어 데이터 분포가 정규 분포에 가깝게 만든다.\n",
    "for i in skew_columns:\n",
    "    data[i] = np.log1p(data[i].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89724852",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 학습 데이터와 테스트 데이터로 분류하기 위해 각각 x와 sub 변수를 만들어 데이터를 나눈다.\n",
    "x = data.iloc[:15035, :]\n",
    "sub = data.iloc[15035:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33cb20e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 가격 예측을 위해 훈련할 모델들을 정하고 random_state를 지정해준다.\n",
    "gboost = GradientBoostingRegressor(random_state=2023)\n",
    "lightgbm = lgb.LGBMRegressor(random_state=2023)\n",
    "rdforest = RandomForestRegressor(random_state=2023)\n",
    "\n",
    "# 각 모델별로 모델과 모델명을 각각 키-값으로 갖는 딕셔너리를 생성하고, 리스트로 감싸준다.\n",
    "models = [gboost, lightgbm, rdforest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2e160c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델을 학습시키고 예측값을 csv 파일로 저장하는 함수를 만든다.\n",
    "def save_submission(model, x, y, sub):\n",
    "    model.fit(x, y)\n",
    "    prediction = model.predict(sub)\n",
    "    prediction = np.expm1(prediction)\n",
    "    submission_path = 'C:/Users/ZAKAR/Documents/GitHub/AIFFEL/Exploration/Quest12_EX02/submission.csv'\n",
    "    submission = pd.read_csv(submission_path)\n",
    "    submission['price'] = prediction\n",
    "    submission_csv_path = f'{data_dir}/submission_{model}.csv'\n",
    "    submission.to_csv(submission_csv_path, index=False)\n",
    "    print(f'{submission_csv_path} saved!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a76354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 모델별로 학습 및 예측 후 결과를 csv 파일로 저장\n",
    "for model in models:\n",
    "    save_submission(model, x, y, sub)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
