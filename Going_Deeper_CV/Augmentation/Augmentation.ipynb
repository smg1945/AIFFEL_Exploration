{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. CutMix와 MixUp 기법을 ResNet50 분류기에 성공적으로 적용하였는가?\n",
    "  - CutMix와 MixUp을 적용한 데이터셋으로 훈련한 각각의 ResNet 모델이 수렴하였다.\n",
    "\n",
    "2. 다양한 실험을 통해 태스크에 최적인 Augmentation 기법을 찾아내었는가?\n",
    "  - 각 Augmentation 기법을 적용하고, 그에 따른 성능 비교 분석 및 문제점을 서술하였음\n",
    "\n",
    "3. 여러가지 Augmentation 기법을 적용한 결과를 체계적으로 비교분석하였는가?\n",
    "  - 기본 Augmentation, CutMix, MixUp이 적용된 결과를 시각화와 함께 체계적으로 분석하였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(ds_train, ds_test), ds_info = tfds.load(\n",
    "    'stanford_dogs',\n",
    "    split=['train', 'test'],\n",
    "    shuffle_files=True,\n",
    "    with_info=True,\n",
    "    as_supervised=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_and_resize_img(image, label):\n",
    "    image = tf.image.resize(image, [224, 224])\n",
    "    return tf.cast(image, tf.float32) / 255., label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment(image,label):\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_crop(image, size=[224, 224, 3])\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_normalize_on_dataset(ds, is_test=False, batch_size=16, with_aug=False):\n",
    "    ds = ds.map(\n",
    "        normalize_and_resize_img,\n",
    "        num_parallel_calls=2\n",
    "    )\n",
    "    if not is_test and with_aug:\n",
    "        ds = ds.map(\n",
    "            augment,\n",
    "            num_parallel_calls=2\n",
    "        )\n",
    "    ds = ds.batch(batch_size)\n",
    "    if not is_test:\n",
    "        ds = ds.repeat()\n",
    "        ds = ds.shuffle(200)\n",
    "    ds = ds.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment2(image,label):\n",
    "    image = tf.image.random_contrast(image, 0.2, 0.5)\n",
    "    image = tf.image.random_hue(image, 0.2)\n",
    "    image = tf.image.random_brightness(image, 0.2)\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clip_box(image_a, image_b):\n",
    "    image_size_x = image_a.shape[1]\n",
    "    image_size_y = image_a.shape[0]\n",
    "\n",
    "    x = tf.cast(tf.random.uniform([], 0, image_size_x), tf.int32)\n",
    "    y = tf.cast(tf.random.uniform([], 0, image_size_y), tf.int32)\n",
    "\n",
    "    width = tf.cast(image_size_x*tf.math.sqrt(1-tf.random.uniform([], 0, 1)), tf.int32)\n",
    "    height = tf.cast(image_size_y*tf.math.sqrt(1-tf.random.uniform([], 0, 1)), tf.int32)\n",
    "\n",
    "    x_min = tf.math.maximum(0, x-width//2)\n",
    "    y_min = tf.math.maximum(0, y-height//2)\n",
    "    x_max = tf.math.minimum(image_size_x, x+width//2)\n",
    "    y_max = tf.math.minimum(image_size_y, y+height//2)\n",
    "\n",
    "    return x_min, y_min, x_max, y_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mix_2_images(image_a, image_b, x_min, y_min, x_max, y_max):\n",
    "    image_size_x = image_a.shape[1]\n",
    "    image_size_y = image_a.shape[0]\n",
    "    middle_left = image_a[y_min:y_max, 0:x_min, :]\n",
    "    middle_center = image_b[y_min:y_max, x_min:x_max, :]\n",
    "    middle_right = image_a[y_min:y_max, x_max:image_size_x, :]\n",
    "    middle = tf.concat([middle_left,middle_center,middle_right], axis=1)\n",
    "    top = image_a[0:y_min, :, :]\n",
    "    bottom = image_a[y_max:image_size_y, :, :]\n",
    "    mixed_img = tf.concat([top, middle, bottom],axis=0)\n",
    "\n",
    "    return mixed_img\n",
    "\n",
    "\n",
    "def mix_2_labels(label_a, label_b, x_min, y_min, x_max, y_max, num_classes=120):\n",
    "    image_size_x = image_a.shape[1]\n",
    "    image_size_y = image_a.shape[0]\n",
    "    mixed_area = (x_max-x_min)*(y_max-y_min)\n",
    "    total_area = image_size_x*image_size_y\n",
    "    ratio = tf.cast(mixed_area/total_area, tf.float32)\n",
    "\n",
    "    if len(label_a.shape)==0:\n",
    "        label_a = tf.one_hot(label_a, num_classes)\n",
    "    if len(label_b.shape)==0:\n",
    "        label_b = tf.one_hot(label_b, num_classes)\n",
    "    mixed_label = (1-ratio)*label_a + ratio*label_b\n",
    "    return mixed_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train_no_aug = apply_normalize_on_dataset(ds_train)\n",
    "for i, (image, label) in enumerate(ds_train_no_aug.take(1)):\n",
    "    if i == 0:\n",
    "        image_a = image[0]\n",
    "        image_b = image[1]\n",
    "        label_a = label[0]\n",
    "        label_b = label[1]\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = ds_info.features[\"label\"].num_classes\n",
    "resnet50_cutmix = keras.models.Sequential([\n",
    "    keras.applications.resnet.ResNet50(\n",
    "        include_top=False,\n",
    "        weights='imagenet',\n",
    "        input_shape=(224,224,3),\n",
    "        pooling='avg',\n",
    "    ),\n",
    "    keras.layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "resnet50_cutmix.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.SGD(learning_rate=0.01),\n",
    "    metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cutmix(image, label, prob=1.0, batch_size=16, img_size=224, num_classes=120):\n",
    "    mixed_imgs = []\n",
    "    mixed_labels = []\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        image_a = image[i]\n",
    "        label_a = label[i]\n",
    "        j = tf.cast(tf.random.uniform([],0, batch_size),tf.int32)\n",
    "        image_b = image[j]\n",
    "        label_b = label[j]\n",
    "        x_min, y_min, x_max, y_max = get_clip_box(image_a, image_b)\n",
    "        mixed_imgs.append(mix_2_images(image_a, image_b, x_min, y_min, x_max, y_max))\n",
    "        mixed_labels.append(mix_2_labels(label_a, label_b, x_min, y_min, x_max, y_max))\n",
    "\n",
    "    mixed_imgs = tf.reshape(tf.stack(mixed_imgs), (batch_size, img_size, img_size, 3))\n",
    "    mixed_labels = tf.reshape(tf.stack(mixed_labels), (batch_size, num_classes))\n",
    "    return mixed_imgs, mixed_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixup_2_images(image_a, image_b, label_a, label_b):\n",
    "    ratio = tf.random.uniform([], 0, 1)\n",
    "    \n",
    "    if len(label_a.shape)==0:\n",
    "        label_a = tf.one_hot(label_a, num_classes)\n",
    "    if len(label_b.shape)==0:\n",
    "        label_b = tf.one_hot(label_b, num_classes)\n",
    "    mixed_image= (1-ratio)*image_a + ratio*image_b\n",
    "    mixed_label = (1-ratio)*label_a + ratio*label_b\n",
    "    \n",
    "    return mixed_image, mixed_label\n",
    "\n",
    "mixed_img, mixed_label = mixup_2_images(image_a, image_b, label_a, label_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixup(image, label, prob=1.0, batch_size=16, img_size=224, num_classes=120):\n",
    "    mixed_imgs = []\n",
    "    mixed_labels = []\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        image_a = image[i]\n",
    "        label_a = label[i]\n",
    "        j = tf.cast(tf.random.uniform([],0,batch_size), tf.int32)\n",
    "        image_b = image[j]\n",
    "        label_b = label[j]\n",
    "        mixed_img, mixed_label = mixup_2_images(image_a, image_b, label_a, label_b)\n",
    "        mixed_imgs.append(mixed_img)\n",
    "        mixed_labels.append(mixed_label)\n",
    "\n",
    "    mixed_imgs = tf.reshape(tf.stack(mixed_imgs), (batch_size, img_size, img_size, 3))\n",
    "    mixed_labels = tf.reshape(tf.stack(mixed_labels), (batch_size, num_classes))\n",
    "    return mixed_imgs, mixed_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot(image, label):\n",
    "    label = tf.one_hot(label, num_classes)\n",
    "    return image, label\n",
    "\n",
    "def apply_normalize_on_dataset(ds, is_test=False, batch_size=16, with_aug=False, with_cutmix=False, with_mixup=False):\n",
    "    ds = ds.map(\n",
    "        normalize_and_resize_img, \n",
    "        num_parallel_calls=2\n",
    "    )\n",
    "    ds = ds.batch(batch_size)\n",
    "    if not is_test and with_cutmix:\n",
    "        ds = ds.map(\n",
    "            cutmix,\n",
    "            num_parallel_calls=2\n",
    "        )\n",
    "    elif not is_test and with_mixup:\n",
    "        ds = ds.map(\n",
    "            mixup,\n",
    "            num_parallel_calls=2\n",
    "        )\n",
    "    else:\n",
    "        ds = ds.map(\n",
    "            onehot,\n",
    "            num_parallel_calls=2\n",
    "        )\n",
    "    if not is_test:\n",
    "        ds = ds.repeat()\n",
    "        ds = ds.shuffle(200)\n",
    "    ds = ds.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_cutmix = apply_normalize_on_dataset(ds_train, is_test=False, with_aug=False, with_cutmix=True, with_mixup=False)\n",
    "ds_mixup = apply_normalize_on_dataset(ds_train, is_test=False, with_aug=False, with_cutmix=False, with_mixup=True)\n",
    "ds_test = apply_normalize_on_dataset(ds_test, is_test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "750/750 [==============================] - 104s 129ms/step - loss: 3.8169 - accuracy: 0.2107 - val_loss: 3.3739 - val_accuracy: 0.2021\n",
      "Epoch 2/10\n",
      "750/750 [==============================] - 94s 126ms/step - loss: 2.9408 - accuracy: 0.4297 - val_loss: 1.4633 - val_accuracy: 0.5946\n",
      "Epoch 3/10\n",
      "750/750 [==============================] - 93s 124ms/step - loss: 2.6525 - accuracy: 0.5242 - val_loss: 1.3654 - val_accuracy: 0.6196\n",
      "Epoch 4/10\n",
      "750/750 [==============================] - 93s 124ms/step - loss: 2.4384 - accuracy: 0.5948 - val_loss: 1.2162 - val_accuracy: 0.6565\n",
      "Epoch 5/10\n",
      "750/750 [==============================] - 93s 124ms/step - loss: 2.2793 - accuracy: 0.6402 - val_loss: 1.1656 - val_accuracy: 0.6824\n",
      "Epoch 6/10\n",
      "750/750 [==============================] - 93s 124ms/step - loss: 2.1641 - accuracy: 0.6837 - val_loss: 1.1260 - val_accuracy: 0.6910\n",
      "Epoch 7/10\n",
      "750/750 [==============================] - 94s 125ms/step - loss: 2.0806 - accuracy: 0.7103 - val_loss: 1.2205 - val_accuracy: 0.6867\n",
      "Epoch 8/10\n",
      "750/750 [==============================] - 97s 130ms/step - loss: 1.9940 - accuracy: 0.7341 - val_loss: 1.2889 - val_accuracy: 0.6645\n",
      "Epoch 9/10\n",
      "750/750 [==============================] - 99s 131ms/step - loss: 1.9426 - accuracy: 0.7481 - val_loss: 1.2094 - val_accuracy: 0.6897\n",
      "Epoch 10/10\n",
      "750/750 [==============================] - 98s 131ms/step - loss: 1.8793 - accuracy: 0.7717 - val_loss: 1.3177 - val_accuracy: 0.6613\n"
     ]
    }
   ],
   "source": [
    "history_cutmix = resnet50_cutmix.fit(\n",
    "    ds_cutmix,\n",
    "    steps_per_epoch=int(ds_info.splits['train'].num_examples/16),\n",
    "    validation_steps=int(ds_info.splits['test'].num_examples/16),\n",
    "    epochs=EPOCH,\n",
    "    validation_data=ds_test,\n",
    "    verbose=1,\n",
    "    use_multiprocessing=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50_mix = keras.models.Sequential([\n",
    "    keras.applications.resnet.ResNet50(\n",
    "        include_top=False,\n",
    "        weights='imagenet',\n",
    "        input_shape=(224,224,3),\n",
    "        pooling='avg',\n",
    "    ),\n",
    "    keras.layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "resnet50_mix.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.SGD(learning_rate=0.01),\n",
    "    metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "750/750 [==============================] - 107s 133ms/step - loss: 3.7564 - accuracy: 0.2286 - val_loss: 3.6833 - val_accuracy: 0.1595\n",
      "Epoch 2/10\n",
      "750/750 [==============================] - 97s 129ms/step - loss: 2.8573 - accuracy: 0.4771 - val_loss: 1.7167 - val_accuracy: 0.5238\n",
      "Epoch 3/10\n",
      "750/750 [==============================] - 99s 132ms/step - loss: 2.5821 - accuracy: 0.5776 - val_loss: 1.5051 - val_accuracy: 0.5869\n",
      "Epoch 4/10\n",
      "750/750 [==============================] - 98s 131ms/step - loss: 2.3805 - accuracy: 0.6488 - val_loss: 1.2670 - val_accuracy: 0.6410\n",
      "Epoch 5/10\n",
      "750/750 [==============================] - 97s 129ms/step - loss: 2.2386 - accuracy: 0.7088 - val_loss: 1.2607 - val_accuracy: 0.6559\n",
      "Epoch 6/10\n",
      "750/750 [==============================] - 97s 130ms/step - loss: 2.1389 - accuracy: 0.7499 - val_loss: 1.2244 - val_accuracy: 0.6615\n",
      "Epoch 7/10\n",
      "750/750 [==============================] - 94s 125ms/step - loss: 2.0786 - accuracy: 0.7768 - val_loss: 1.2244 - val_accuracy: 0.6610\n",
      "Epoch 8/10\n",
      "750/750 [==============================] - 94s 125ms/step - loss: 2.0496 - accuracy: 0.7776 - val_loss: 1.2777 - val_accuracy: 0.6502\n",
      "Epoch 9/10\n",
      "750/750 [==============================] - 94s 126ms/step - loss: 1.9905 - accuracy: 0.8016 - val_loss: 1.2273 - val_accuracy: 0.6690\n",
      "Epoch 10/10\n",
      "750/750 [==============================] - 92s 122ms/step - loss: 1.9501 - accuracy: 0.8141 - val_loss: 1.3011 - val_accuracy: 0.6615\n"
     ]
    }
   ],
   "source": [
    "history_mixup = resnet50_mix.fit(\n",
    "    ds_mixup,\n",
    "    steps_per_epoch=int(ds_info.splits['train'].num_examples/16),\n",
    "    validation_steps=int(ds_info.splits['test'].num_examples/16),\n",
    "    epochs=EPOCH,\n",
    "    validation_data=ds_test,\n",
    "    verbose=1,\n",
    "    use_multiprocessing=True,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CutMix와 MixUp의 비교 실험에서, 9 epoch 까지는 전반적으로 CutMix가 더 나은 성능을 보여주고 있음을 확인할 수 있었지만, 학습이 더 진행될수록 두 모델의 성능 차이는 점차 줄어들었다.\n",
    "\n",
    "만약 학습할 수 있는 데이터의 양이 더 충분하였더라면 두 모델의 분명한 성능 차를 기대할 수 있을 것 같다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CutMix와 Mixup을 비교하였으니 이제 다양한 Augmentation 기법들을 적용한 모델들의 성능을 비교해보자.\n",
    "\n",
    "앞의 코드에서는 좌우반전 및 무작위 분할을 하는 augment()와 명도, 색상, 채도를 조절한 augment2() 함수를 구현하였다.\n",
    "\n",
    "각각의 함수를 적용한 데이터로 훈련된 모델의 성능을 비교해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = ds_info.features[\"label\"].num_classes\n",
    "def onehot_(image, label):\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    image = tf.squeeze(image)\n",
    "    label = tf.cast(label, tf.int32)\n",
    "    label = tf.one_hot(label, num_classes)\n",
    "    return image, label\n",
    "\n",
    "def apply_normalize_and_aug(ds, is_test=False, batch_size=16, with_aug1=False, with_aug2=False):\n",
    "    ds = ds.map(\n",
    "        normalize_and_resize_img, \n",
    "        num_parallel_calls=2\n",
    "    )\n",
    "    if not is_test and with_aug1:\n",
    "        ds = ds.map(\n",
    "            augment,\n",
    "            num_parallel_calls=2\n",
    "        )\n",
    "    elif not is_test and with_aug2:\n",
    "        ds = ds.map(\n",
    "            augment2,\n",
    "            num_parallel_calls=2\n",
    "        )\n",
    "    ds = ds.map(\n",
    "        onehot_,\n",
    "        num_parallel_calls=2\n",
    "    )\n",
    "    ds = ds.batch(batch_size)\n",
    "    if not is_test:\n",
    "        ds = ds.repeat()\n",
    "        ds = ds.shuffle(200)\n",
    "    ds = ds.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_aug1 = apply_normalize_and_aug(ds_train, is_test=False, batch_size=16, with_aug1=True, with_aug2=False)\n",
    "ds_aug2 = apply_normalize_and_aug(ds_train, is_test=False, batch_size=16, with_aug1=False, with_aug2=True)\n",
    "ds_aug_test = apply_normalize_and_aug(ds_test, is_test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50_aug1 = keras.models.Sequential([\n",
    "    keras.applications.resnet.ResNet50(\n",
    "        include_top=False,\n",
    "        weights='imagenet',\n",
    "        input_shape=(224,224,3),\n",
    "        pooling='avg',\n",
    "    ),\n",
    "    keras.layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "resnet50_aug1.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.SGD(learning_rate=0.01),\n",
    "    metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "750/750 [==============================] - ETA: 0s - loss: 2.2405 - accuracy: 0.4423"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"c:\\Users\\ZAKAR\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1727, in test_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\ZAKAR\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1713, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\ZAKAR\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1701, in run_step  **\n        outputs = model.test_step(data)\n    File \"c:\\Users\\ZAKAR\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1665, in test_step\n        y_pred = self(x, training=False)\n    File \"c:\\Users\\ZAKAR\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\ZAKAR\\anaconda3\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 295, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_2\" is incompatible with the layer: expected shape=(None, 224, 224, 3), found shape=(None, None, 224, 224, 3)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m history_aug1 \u001b[39m=\u001b[39m resnet50_aug1\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m      2\u001b[0m     ds_aug1,\n\u001b[0;32m      3\u001b[0m     steps_per_epoch\u001b[39m=\u001b[39;49m\u001b[39mint\u001b[39;49m(ds_info\u001b[39m.\u001b[39;49msplits[\u001b[39m'\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mnum_examples\u001b[39m/\u001b[39;49m\u001b[39m16\u001b[39;49m),\n\u001b[0;32m      4\u001b[0m     validation_steps\u001b[39m=\u001b[39;49m\u001b[39mint\u001b[39;49m(ds_info\u001b[39m.\u001b[39;49msplits[\u001b[39m'\u001b[39;49m\u001b[39mtest\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mnum_examples\u001b[39m/\u001b[39;49m\u001b[39m16\u001b[39;49m),\n\u001b[0;32m      5\u001b[0m     epochs\u001b[39m=\u001b[39;49mEPOCH,\n\u001b[0;32m      6\u001b[0m     validation_data\u001b[39m=\u001b[39;49mds_aug_test,\n\u001b[0;32m      7\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[0;32m      8\u001b[0m     use_multiprocessing\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m      9\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\ZAKAR\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filemp_es4ue.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__test_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\Users\\ZAKAR\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1727, in test_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\ZAKAR\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1713, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\ZAKAR\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1701, in run_step  **\n        outputs = model.test_step(data)\n    File \"c:\\Users\\ZAKAR\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1665, in test_step\n        y_pred = self(x, training=False)\n    File \"c:\\Users\\ZAKAR\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\ZAKAR\\anaconda3\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 295, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_2\" is incompatible with the layer: expected shape=(None, 224, 224, 3), found shape=(None, None, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "history_aug1 = resnet50_aug1.fit(\n",
    "    ds_aug1,\n",
    "    steps_per_epoch=int(ds_info.splits['train'].num_examples/16),\n",
    "    validation_steps=int(ds_info.splits['test'].num_examples/16),\n",
    "    epochs=EPOCH,\n",
    "    validation_data=ds_aug_test,\n",
    "    verbose=1,\n",
    "    use_multiprocessing=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50_aug2 = keras.models.Sequential([\n",
    "    keras.applications.resnet.ResNet50(\n",
    "        include_top=False,\n",
    "        weights='imagenet',\n",
    "        input_shape=(224,224,3),\n",
    "        pooling='avg',\n",
    "    ),\n",
    "    keras.layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "resnet50_aug2.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.SGD(learning_rate=0.01),\n",
    "    metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_aug2 = resnet50_aug2.fit(\n",
    "    ds_aug2,\n",
    "    steps_per_epoch=int(ds_info.splits['train'].num_examples/16),\n",
    "    validation_steps=int(ds_info.splits['test'].num_examples/16),\n",
    "    epochs=EPOCH,\n",
    "    validation_data=ds_aug_test,\n",
    "    verbose=1,\n",
    "    use_multiprocessing=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history_aug1.history['val_accuracy'], 'r')\n",
    "plt.plot(history_aug2.history['val_accuracy'], 'b')\n",
    "plt.plot(history_cutmix.history['val_accuracy'], 'g')\n",
    "plt.plot(history_mixup.history['val_accuracy'], 'y')\n",
    "plt.title('Model validation accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['With aug1', 'With aug2'. 'With cutMix', 'With mixUp'], loc='upper left')\n",
    "plt.grid(True)\n",
    "plt.ylim(0.1, 0.8)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결과를 보면, 좌우반전과 무작위 분할을 하는 augment() 함수를 적용한 데이터로 훈련된 모델이 더 나은 성능을 보여주었다. 또한 앞서 실험하였던 CutMix와 MixUp 모델들보다도 높은 검증 정확도를 보여준다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결론적으로, CutMix나 MixUp 등이 다른 Augmentation 기법보다 분명한 성능 차이를 보이려면 충분한 epoch로 모델을 학습시켜야 하며, 이미지의 RGB 값을 변형한 데이터보다 이미지 자체의 크기나 픽셀의 위치 등을 변경한 데이터로 모델을 훈련시키는 것이 더 나은 성능을 기대할 수 있다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
